{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aafd500-4e6c-4f54-86fb-0e000bd06dcc",
   "metadata": {},
   "source": [
    "# Створення базових моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c115768-b336-4a31-b9eb-3ec88520226a",
   "metadata": {},
   "source": [
    "**Частина 1**\n",
    "\n",
    "Необхідно визначити в коді натупне:\n",
    "\n",
    "1. Базову модель для навчання (виберіть який тип моделі хочете натренувати CNN, MLP тощо).\n",
    "2. Початкову кількість шарів та їх параметри.\n",
    "3. Функції для тренування та валідації, візуалізації результатів, фінкцію втрат та метрику перевірки результатів.\n",
    "4. Натренуйте модель і перевірте результат. Яке значення функції втрат, яка метрика вашої моделі після навчання? Візуалізуйте графіки навчання. Скільки часу потрібно було на тренування?\n",
    "\n",
    "**Частина 2**\n",
    "\n",
    "1. Опишіть гіперпараметри моделі: кількість шарів/кількість нейронів в шарах, різні їх комбінації.\n",
    "2. Підберіть та перевірте найкращі гіперпараметри вашої моделі за яких метрика під час валідації буде найвищою. Скільки часу потрібно було на підбір гіперпараметрів моделі?\n",
    "3. Продемонструйте на яких класах та зображеннях найчастіше помиляється найкраща модель.\n",
    "4. Візуалізувати графіки залежностей між гіперпараметрами найкращої моделі і змінами значень її метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec280db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: torch in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: matplotlib in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: torchvision in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: plotly in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (5.18.0)\n",
      "Requirement already satisfied: pandas in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: PyYAML in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from optuna) (1.12.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from optuna) (2.0.23)\n",
      "Requirement already satisfied: numpy in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from optuna) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: colorlog in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: networkx in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: fsspec in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: requests in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: Mako in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna torch matplotlib torchvision plotly pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649ad8f7-0681-4ee0-aede-f9fce7035c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb8e3ba-17b0-45d5-b5d4-8d7b6b8fc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d0f45f-baeb-42ed-bcec-dcd32bfe6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = './datasets'\n",
    "\n",
    "train_dataset = FashionMNIST(\n",
    "    datasets_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "validation_dataset = FashionMNIST(\n",
    "    datasets_path,\n",
    "    train=False,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63181c3e-4d1e-404b-ae5a-a89eda0cc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81c3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_size = 2\n",
    "plt_images = 8\n",
    "IMAGE_SIZE = 28\n",
    "CLASSES_N = len(set([i.item() for x,y in train_loader for i in y]))\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES=20\n",
    "N_VALID_EXAMPLES=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de6763a-a9dd-4b63-8870-1693089b7d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABOwAAACuCAYAAACFmpLxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7f0lEQVR4nO3dd5RVVZr+8RcJRagqilzknLNEwQZpYyvdGEDUnlG6zWnUpZh7dGxXt6PT5tYxTesYUXu6p3UcMY8BEBSQILnIORYgUTi/P2bk59nvg3W8VFGnLt/PWq7V+2XfW6fq7rvPuaernrdSFEWRAQAAAAAAAEiFo8r7AAAAAAAAAAD8f9ywAwAAAAAAAFKEG3YAAAAAAABAinDDDgAAAAAAAEgRbtgBAAAAAAAAKcINOwAAAAAAACBFuGEHAAAAAAAApAg37AAAAAAAAIAU4YYdAAAAAAAAkCJZf8OuVatWNmbMmPI+DByBWHsoD6w7lAfWHcoLaw/lgXWH8sC6Q3lg3ZWvCnvDbtGiRXbppZdamzZtrHr16pafn2+DBw+2hx56yHbu3Fneh5eRefPm2XXXXWeDBg2y6tWrW6VKlWzJkiXlfVgIZOPaMzNbuXKlnX322VZQUGD5+fk2YsQIKyoqKu/Dwv/J1nVnZjZu3Dg75phjrFatWlZQUGCDBg2yDz74oLwPC5ad645zbcWQjWvPzOyVV16xo48+2qpXr24NGjSwCy+80DZs2FDeh4X/k63rzoxzbZpl47r7y1/+YieffLI1adLEcnJyrFmzZjZy5EibNWtWeR8a/k82rrs777zTKlWq5P6rXr16eR9axqqU9wFk4r/+679s1KhRlpOTY+eff75169bN9uzZY59++qmNHTvWZs+ebU8++WR5H+aPNnHiRHv44YetS5cu1rlzZ5s+fXp5HxIC2br2tm/fbsOGDbPi4mK79dZbrWrVqvbAAw/Y0KFDbfr06VavXr3yPsQjWrauO7P/PbHeddddNnLkSBszZozt3bvXZs2aZStXrizvQzviZeu641ybftm69h5//HG74oor7Pjjj7f777/fVqxYYQ899JB98cUX9vnnn1foDxTZIFvXnRnn2jTL1nU3c+ZMq1Onjl1zzTVWv359W7Nmjf3bv/2b9e/f3yZOnGg9e/Ys70M8omXruvvO448/brm5uQfGlStXLsejOURRBVNUVBTl5uZGnTp1ilatWuX+fcGCBdGDDz54YNyyZcvoggsuOIxHmLmNGzdGW7dujaIoiu67777IzKLFixeX70HhgGxee//8z/8cmVk0efLkA7U5c+ZElStXjm655ZZyPDJk87qbOHFiVKlSpej+++8v70NBIJvXHefadMvWtbd79+6ooKAgGjJkSLR///4D9TfeeCMys+jhhx8ux6NDtq67KOJcm2bZvO6UNWvWRFWqVIkuvfTS8j6UI1o2r7s77rgjMrNo/fr15X0opabC/Unsvffea9u3b7dnnnnGGjdu7P69Xbt2ds011xz08Zs2bbIbbrjBunfvbrm5uZafn28/+9nP7KuvvnJzH3nkEevatavVrFnT6tSpY3379rWXXnrpwL9v27bNrr32WmvVqpXl5ORYw4YN7cQTT7SpU6cemLNjxw6bO3duoj93qFu3ruXl5ZU4D+Ujm9fe66+/bv369bN+/fodqHXq1MmOP/54e/XVV0t8PMpONq+7Bx980AoLC+2aa66xKIps+/btJT4Gh0c2rzvOtemWrWtv1qxZtmXLFhs9erRVqlTpQH348OGWm5trr7zyyg8+HmUrW9edGefaNMvmdac0bNjQatasaVu2bMno8SgdR8K6i6LItm7dalEUJX5MWlW4G3ZvvPGGtWnTxgYNGpTR44uKiuyvf/2rDR8+3O6//34bO3aszZw504YOHWqrVq06MO+pp56yf/iHf7AuXbrYgw8+aP/0T/9kvXr1ss8///zAnMsuu8wef/xxO+uss+yxxx6zG264wWrUqGFz5sw5MGfy5MnWuXNne/TRRzP/ppEK2br29u/fbzNmzLC+ffu6f+vfv78tWrTItm3bltH3jEOXrevOzOz999+3fv362cMPP2wNGjSwvLw8a9y4MftlCmTzukO6Zeva2717t5mZ1ahRw/1bjRo1bNq0abZ///6Mvmccumxdd2aca9Msm9fdd7Zs2WLr16+3mTNn2kUXXWRbt261448/PqPvF6XjSFh3bdq0sdq1a1teXp793d/9na1duzaj7zUVyvcX/H6c4uLiyMyiESNGJH5M+Cucu3btivbt2xebs3jx4ignJye66667DtRGjBgRde3a9Qefu3bt2tGVV175g3M+/PDDyMyiO+64I/ExRxF/ppM22bz21q9fH5lZ7Bi+88c//jEys2ju3Lk/+BwoG9m87jZt2hSZWVSvXr0oNzc3uu+++6Jx48ZFp5xySmRm0b/+67/+4ONRdrJ53YU416ZLNq+99evXR5UqVYouvPDCWH3u3LmRmUVmFm3YsOEHnwNlI5vXHefa9Mrmdfd9HTt2PLDH5ebmRrfffrs7Zhw+2b7uHnzwweiqq66KXnzxxej111+PrrnmmqhKlSpR+/bto+Li4hIfn0YVqunE1q1bzcwO6U9ZcnJyDvzvffv22ZYtWyw3N9c6duwY+9XLgoICW7FihU2ZMiX2Z4LfV1BQYJ9//rmtWrXKmjRpIuccd9xxWfGrmEe6bF5733UB+v7xfee7AOyK2imoosvmdffdn+Rs3LjRXnnlFRs9erSZmY0cOdK6d+9ud999t1166aWJv0+Unmxed0i3bF579evXt7PPPtuee+4569y5s51xxhm2cuVKu/rqq61q1aq2d+9ezrXlJJvXHefa9Mrmdfd9f/rTn2zr1q1WVFRkf/rTn2znzp22b98+O+qoCveHflkh29dd+Ke8Z511lvXv399++ctf2mOPPWY333xzoudJkwr1TsnPzzczO6Q/z9u/f7898MAD1r59e8vJybH69etbgwYNbMaMGVZcXHxg3k033WS5ubnWv39/a9++vV155ZX22WefxZ7r3nvvtVmzZlnz5s2tf//+duedd1pRUVHGx4b0yua1992f53z35zrft2vXrtgcHF5HwrqrWrWqjRw58kD9qKOOstGjR9uKFSts2bJlGT03Dk02rzukW7avvSeeeMJOPfVUu+GGG6xt27Y2ZMgQ6969u/385z83M4t1tMPhk83rjnNtemXzuvu+Y445xk4++WS7/PLLbfz48fbCCy/YLbfccsjPi8wcKevu+8477zwrLCy09957r1Sf97Apv1/uy0yTJk2itm3bJp4f/grnb3/728jMol//+tfRyy+/HI0fPz569913o65du0ZDhw6NPXb79u3RK6+8Eo0ZMyZq1KhRZGbRP/7jP8bmrFq1KvrjH/8YjRgxIqpZs2ZUvXr16K233jqUbzGKIv5MJ42yde3t27cvysnJiS6//HL3b7fffntkZgc6KuLwy+Z1V7169aiwsND92+OPPx6ZWTR9+vQf/bwoHdm67kKca9PnSFh7S5cujf7nf/4nWrJkSRRFUXTMMcdEDRo0OKTnxKHJ1nXHuTbdsnXd/ZBzzz1XrkccPkfiuuvXr1/Uu3fvUn3Ow6XC3bC75JJLIjOLJkyYkGh+uMB69uwZDRs2zM1r2rSpW2Dft3v37ui0006LKleuHO3cuVPOWbt2bdS0adNo8ODBiY7th/AhIn2yee317ds36tevn6ufeOKJUZs2bTJ6TpSObF53AwcOjCpXrhzt3r07Vv/Nb34TmVm0cuXKjJ4Xhy6b1933ca5NnyNl7X1n8+bNUbVq1aJzzz231J4TP142rzvOtemVzevuYE4//fSoRo0apfqc+HGOtHW3f//+qEGDBtFJJ51Uas95OFWoP4k1M7vxxhutVq1adtFFF8luH4sWLbKHHnrooI+vXLmy+xvo1157zVauXBmrbdy4MTauVq2adenSxaIosr1799q+fftiv/Jp9r+tqps0aRL708JDbX+N9MjmtTdy5EibMmWKffHFFwdq8+bNsw8++MBGjRpV4uNRdrJ53Y0ePdr27dtnzz333IHarl277MUXX7QuXbocNMsCZS+b1x3S7Uhbe7fccot9++23dt1112X0eJSObF53nGvTK5vX3bp161xtyZIl9v7771vfvn1LfDzKTjavu/Xr17va448/buvXr7dTTjmlxMenUYVqOmFm1rZtW3vppZds9OjR1rlzZzv//POtW7dutmfPHpswYYK99tprNmbMmIM+fvjw4XbXXXfZr371Kxs0aJDNnDnTXnzxRWvTpk1s3kknnWSFhYU2ePBga9Sokc2ZM8ceffRRO+200ywvL8+2bNlizZo1s5EjR1rPnj0tNzfX3nvvPZsyZYr94Q9/OPA8kydPtmHDhtkdd9xhd9555w9+b8XFxfbII4+YmR34++5HH33UCgoKrKCgwK666qrMfmgoFdm89q644gp76qmn7LTTTrMbbrjBqlatavfff781atTIrr/++kP5seEQZfO6u/TSS+3pp5+2K6+80ubPn28tWrSw559/3pYuXWpvvPHGofzYcIiyed1xrk23bF5799xzj82aNcsGDBhgVapUsb/+9a/2zjvv2N13333QQG4cHtm87jjXplc2r7vu3bvb8ccfb7169bI6derYggUL7JlnnrG9e/faPffccyg/NhyibF53LVu2tNGjR1v37t2tevXq9umnn9orr7xivXr1qrgNdg7/L/WVjvnz50cXX3xx1KpVq6hatWpRXl5eNHjw4OiRRx6Jdu3adWCeakN8/fXXR40bN45q1KgRDR48OJo4cWI0dOjQ2K9wPvHEE9GQIUOievXqRTk5OVHbtm2jsWPHHmgHvHv37mjs2LFRz549o7y8vKhWrVpRz549o8ceeyx2nD+mDfHixYsPtL0O/2vZsuWh/LhQirJx7UVRFC1fvjwaOXJklJ+fH+Xm5kbDhw+PFixYkPHPCaUrW9fd2rVrowsuuCCqW7dulJOTEw0YMCB6++23M/45oXRl47rjXFsxZOPae/PNN6P+/ftHeXl5Uc2aNaOBAwdGr7766iH9nFC6snHdRRHn2rTLxnV3xx13RH379o3q1KkTValSJWrSpEl0zjnnRDNmzDiknxVKTzauu4suuijq0qVLlJeXF1WtWjVq165ddNNNN1XoPPZKUfQjezMDAAAAAAAAKDMVLsMOAAAAAAAAyGbcsAMAAAAAAABShBt2AAAAAAAAQIpwww4AAAAAAABIEW7YAQAAAAAAACnCDTsAAAAAAAAgRbhhBwAAAAAAAKRIlfI+gEO1YsWK2LhDhw5uTqtWrVwtiiJX+/bbb2Pj3NxcN2fTpk2utnr16ti4adOmbs7OnTtdbe3ata725z//OTY+88wz3RxUXOFaMTMbO3ZsbLx79243Z+/eva7WpUuX2Ph3v/vdIR4dstnEiRNd7W9/+1ts/Itf/MLNqVu3rqv99re/jY1btGjh5rAes9uOHTtcTZ3n8vPzXa1q1aplckxmZhs3bnQ1tYYrVapUZscA4PBT1/Xh+3zPnj1uzty5c12tR48eP/q5y8P+/ftd7aij/O9iLFy4MDauXbu2m9OgQYMSn189N9LhpZdecrXq1avHxkk/U44bNy42rlLF3y4466yzfsTRATgU7LwAAAAAAABAinDDDgAAAAAAAEgRbtgBAAAAAAAAKcINOwAAAAAAACBFKnzTiUmTJsXGKvRaNYrYvn27q4Uh2iosWwXPVq5cOTYuKChwc8LgTzPddOLZZ5+NjWk6UTEsWbLE1ebNm5foseG8r776ys1RTSfmz58fG//kJz9xc1TYeq1atVytU6dOsbEKmIV3KEHU6rGZPlfo7bffdrXXXnvN1TZv3hwbn3baaW5OXl6eq4XB0++//76bc+utt7qaauSTqbL8+aFkLVu2dLUNGzaU2vOr1y58zVUAugphDxv7mJnde++9h3B0ACqiffv2uZpqyBQ2nUjruSTJedDMbNasWbFxt27d3BzVdALppM5zjz76qKtt27YtNr755pvdHPWeqFmzZmwcrh+z5GsPwKHjN+wAAAAAAACAFOGGHQAAAAAAAJAi3LADAAAAAAAAUqTCB1UVFRWVOEdlT1StWtXVwqwmlRGgnivM+1q6dKmb06hRoxIfZ6azylC+Vq9e7WphRlhOTk6i5xo4cKCrhblhav2ozMXatWvHxl27dnVzZsyY4WorVqxwtalTp5b4XH369HG1I92h5Npk+tjp06fHxip/Z/z48a6msuj27NkTG4eZdmZmderUcbUOHTrExjfeeKObc9ttt7lamKdi5rMXR44c6eaoY09rplC22r17d2y8ZcsWN6dz586utmvXLlerVq1abLxx40Y3R+W+ho9TGXaqVprZegAqrho1arha7969XS08N4Z7j1nmGV5J8jmTCjO0D6ZZs2axcdOmTRM9Tu2nKH/qdVFroUmTJrFx0nUcrv/GjRv/2EMEUIrYiQEAAAAAAIAU4YYdAAAAAAAAkCLcsAMAAAAAAABShBt2AAAAAAAAQIpU+KYTKvg6pJpHqJDNMAhWhXqqRhFhGPe+ffvcHHWcubm5rrZmzRpXQ/n66KOPXK1Vq1axca1atdwcFba+adMmVwsbVpx33nluzjvvvONq3bt3L/E4O3bs6GpJAo/nzJnj5rRt29bVCgoKXA2Z+dvf/uZq7777rquFP/OWLVu6Of/yL//ias8884yrhUHUYQMUM7Njjz3W1Z5//vnYWIX6DxkyxNXUepk5c2ZsfPHFF7s5ffv2dbXrrrsuNk4avo3MLFmyJDZW59XwXGim98HwsarBxLfffutqYaMdda5Vpk2blmgeslu47tQ1nmq8c9NNN8XG7dq1c3MWLFjgauq6Lz8/PzZWDatU87HCwsLYWDUyU83UVHOB8LH9+vVzcyqiJNf1imqsNG/evNg4vN5K+txJleZzqWZjX375ZWyszqlK+J5R+776XITDb8eOHa4WNuxSr5Vae+EepJ4bwOHDb9gBAAAAAAAAKcINOwAAAAAAACBFuGEHAAAAAAAApAg37AAAAAAAAIAUqfBJoSrsPKTCq5ME7ysqIDhJKKsK3laB2UmOAWVn+fLlrqbC7MNwZ/X6qkBr5ac//WlsvGfPHjdnxIgRrhY2KFENJr755ptExxAG0armAFOnTnW18NiR3KOPPhobr1u3zs057rjjSnwetY98/PHHrta7d29Xa9iwYWz86quvujmqOc4ZZ5wRG6t9S+2DixcvdrVwfz755JPdHPWzefLJJ2Pjyy+/3M1B6QlDyxW156mGPDVr1oyNVdB/kkYU6jyuQrWLi4tdLVxT4XsB2SdJ0wm1Vp566qnYuFOnTm7O3LlzXS1sMGHmz63Lli2Tx1qSMEzeTF+rqH04bLIQNpSpqJJec4W2bt3qamHjpkGDBrk5w4YNc7Vu3bpldAxKeG5funSpm/PBBx+42uzZs10tbAhUVFTk5rRp08bVwp9ppj9jlL2dO3eWOEe9fur6LdxL1L4I4PBh5wUAAAAAAABShBt2AAAAAAAAQIpwww4AAAAAAABIEW7YAQAAAAAAAClS4ZtOhEGqStgg4GCPC4M3VVhv0hD/UNJw4yZNmmT0/CgdX3/9taupIOewyYRqRqKanWzfvt3VwnW2d+9eN0eFV4cBwarxRdLmKuGxquB21eAlSYh3NlMNH9R6WbhwoauFe0mfPn0SfU211kKFhYWJnisM/x8wYICbo/bPcI2qn4MKU1d7aocOHWJjtfbU9xwGhauGMc2bN3c1tf7V+wRxSYLpVRC+eu22bNkSG6s9T71OYai2akyh1qsK4w6b6JxyyiluDrJLkvNTs2bNXG3gwIGx8cqVK92cFi1auJpqBLVt27bYWF0T1KtXz9XCa1b1vlL7cLVq1VwtW9f6okWLXK1BgwaxsWqeM27cOFc7+uijY+NVq1a5Offff7+rqdcufK3UeVBdN6i1EVJrWjWPCD9v3HPPPW6OugYJn0utabX2Oc+WrS+++MLV1OfTcF2p9aL2jfA6TH1enT9/vquF13PIfmo/Ky1qvarP1upzQxLqucKGPK+//nqi57r11lszOoakjqxP1wAAAAAAAEDKccMOAAAAAAAASBFu2AEAAAAAAAApUuEz7AoKCkqckzRXK8zRUfk4SfLM1OPU31erjIf69euXeJwoPRs3boyNVQaEykQK/+69Vq1aib6eymoK//5fZc6ojInwWNUaq1Onjqtt2rTJ1cJ1vWPHDjdH5T6GmX/dunVzc6CzPsLXRmW+qWyYMLtN7TcqUyJJdomak5ub62oh9b4Js4MO9lzh15w7d66bozIcw6ygmTNnujkqwy5pfhDiwoxA9ZqoPUid08Jzn8pqUtkiNWrU+MHxwb6eeq7wfYTslyRDS2XBTpo0KTZWOXdNmzZ1NbXuwpw19T5SebFhDqM6BvX+U9cO6n2TJuH+oF439TpdeeWVrta3b9/YOLzmO9jzh9d96lzSunVrV1OvXXjtVLduXTdHnXvDWuPGjd0ctcb27NnjauHaUOfiFStWuNrs2bNj4w8++MDN+f3vf+9q5NWVLZVTqN7X4euu9gP1WoVrL8w7NjNr1KhRiceJ7He4s8uT5tX9+c9/jo3VXvnmm2+6Wpix/POf/9zNCXNtD6Y0c975DTsAAAAAAAAgRbhhBwAAAAAAAKQIN+wAAAAAAACAFOGGHQAAAAAAAJAiFb7phAphzVROTk5svHnz5kSPC0ODVahn+NwHo0LmUXamTJkSG6tgVdWAIQxFVg0ZVJC9amARNplQAbAqLFM1GwipZgCq2Ul4XKoxRe3atV1t3rx5sfGR1nQiabOCoqIiVzv22GNj4wceeMDNUU112rVrFxur9amoNRSud/Uaq+cPj0s1mFD7oAq6XrVq1Q8ek5neP8PvJwyKPRgaTGQm3CPUnqdCr1UAekg12lFNIcJ5eXl5iY5Bveaq0QWyW5JmBip4P6Qam6h1t379elcLm0eo/a5JkyauFr4fVAMrdT08ffp0V2vYsKGrVTSqedCAAQNcLdynVFj/4sWLXW3NmjWxsWospvYQ1egrXBtqXai9LDzPhudKM7Pi4mJXC68RzPz5WDXtUNcb4VpX6w6Hn9o31OeLJHue+kyQ5LmTNttDdluyZImrhZ9PCwsLS+3rqWvKZ5991tVuuumm2PiEE05wc84//3xXU00mMlWaDTn4DTsAAAAAAAAgRbhhBwAAAAAAAKQIN+wAAAAAAACAFOGGHQAAAAAAAJAiFb7phApJD6mwTGX16tWx8XXXXefmhEG0ZmYvv/xybHwojSNU6CvKTt++fWPjSZMmuTlffPGFq4Xh5+ecc46bE64nMx2eH4Ynq5BKFRQbUo/btm2bq6mA9/A98sknn7g5ffr0cTX1fcMLg8bNzOrVqxcbqxBtFTLdvHnz2FiF/6t1pl73cM2oQGl17OHXVHusWrNjx451tdtuuy02VmtWhXSHweyqSQFKT7heD6XpRJUq8UsP9TgVip4kCF5dE6g1RfORI0+ScHXVZCdcr127dnVzNm7c6Gpq3wob77Rs2dLNUQ17wgZSqimaWvtqnZdmAHhZSBKUr86NEyZMcLVhw4bFxmovmDNnjqv16NEjNlYNk1QjpyRNGdTeGa4xM39NoM6zqsmF+nktX748NlY/B9XsJPweVSOzpJK8rihbas2qPSLcg9RrVZqB+qi4XnjhhYwep67Z1foMqQZzzZo1c7Wnn346Nu7cubOb06VLlxK/XlLqM1wSSd9HvNsAAAAAAACAFOGGHQAAAAAAAJAi3LADAAAAAAAAUqTCZ9i1bdu2xDkql0HljYR++ctfutqGDRtcLcywq1+/vpuj/i572bJlrtagQYMSjwulJ3ythg8f7uasWLHC1Z555pnYOMzCMzNr3LixqxUXF7tamC2m8mtUdkmYLab+Dl7lqeTl5bnarFmzYuPWrVu7OVdddZWrkWHhqWwY9f4Pf3ZqbSTJ6FSvscokUbl24TyVo6MelyQXVM0566yzXC08fvX1ioqKXK1Tp06xsco0UnlUNWvW9AeLEiX5uan9QOXMha+nWhcnnXSSqz3wwAOxcfXq1d0ctX7Uug4z+ZD9kuQWzp0719XC/Ca1V2/atMnVVKZNeL5X14Eqv1FlQYaS5t9mw3lbXYur7yu8xps6daqbo7KLwz3jjDPOcHNUJqI6H4fn/0aNGrk56rov/B7VXlq3bl1XUxlP4bHOnz/fzVGflcKvqbITVV6zuv5F6UmSx2nm3xNJ3/vhPqX2sqTHgOyR5Dxk5vfdbt26uTlLlixxtfbt28fGqm/A+PHjXU19ZlXXlWWprM+rFf+sDQAAAAAAAGQRbtgBAAAAAAAAKcINOwAAAAAAACBFuGEHAAAAAAAApEiFbzrRo0eP2FiFS9eoUcPVVBBvaPny5a6mwmJDubm5rpY0qLFly5aJ5uHwueyyy1wtDNRVAb7qtVTrIFyfqkGBCs8PqbB1FY6tnqtdu3ax8ZgxY0r8etC++eYbV1OvTUjtNyrEtKCgIDZWAeXqcUkCUVWwsFqPKiA7pNaeas4ShlirPbxVq1auFn4/6jhVQDZNJzLTq1ev2Fg1FQmDqs38ejUz2717d2xcWFjo5qi1EjadUA10VGMBFdZOYDaUDz/80NXCBiWqEZUKx1YNCMK1r9ah2qPC51LNzdTeqfZqtTenSZLr88WLF7tax44dXS38eavmROpn1Llz59hYXbupc04SST8PhPubWk+qwYS63ghD2T/66CM3R13HDhgwIDYOf55mZuvWrXM1mk6ULdWsRr1vwnNy0rUXnt/Ve2T9+vWups7lSB91rZ/kM8I555zjatdcc42rDR06tMTnOvbYY0uco0ycONHVPvjgA1c78cQTY+NmzZq5OWoPV+fRTH399dexcX5+vpujjkvhN+wAAAAAAACAFOGGHQAAAAAAAJAi3LADAAAAAAAAUoQbdgAAAAAAAECKVPimE2HApQqX3r59u6slCYtV4fydOnUq8XEqzFEFdCtJwwdRvsKwTLVWVECwmheGUKq1qQKtwyB+9TjVAEGFstepU8fVQpmGlB5pNmzY4GqqEU0YDL1z5043RwU8h+tKvZ5J9xv1mmZCBRKr4HQVTh0eq1pT6ue3du3a2FgFbW/dutXVmjZt6mooWf/+/WNjFXCtAvRVY4hwv+nTp4+bM2zYsBKPSb0/1FpRIftJgu1x5Jk5c6arhY1Tateu7eaoRhTqejTcr9WeqNZm+FxqvwubY6ivZ2Y2d+5cV0uTJO/NOXPmuJoK9F6yZElsrML61V7ToUOH2Fg1hVLXeHXr1nW18PtRYf3q2MNzqNpfVdMJ1aQpnKea+ixdutTVwutKdQzqZ9OzZ09XY88tPTNmzHA1de0UXuOp10+9LmFNBfFPnTrV1U499VR/sEidJJ/nHnvsMTcnvA40S9ZgIulnjSSfKdV1vfoMO2XKlNhY3V9J0mBCNWpR59AJEya4WlFRUWz8k5/8xM2h6QQAAAAAAABQAXHDDgAAAAAAAEgRbtgBAAAAAAAAKcINOwAAAAAAACBFKnzTiZAKHlRh7ip4M6QCZZOE86sA9qTh/A0bNkw0D+mi1li1atVcTa2pcL2o5hEqmLp79+6xcRiubKabD6jwTxXKHiIwOJlt27a5mmrAEAaZqrWhgqhViHgoSfiwmV+jNWrUSPRcYeC5WmeqIYAKSg/Xu1pnqpFAeOzqPaiariAzKmg/tHnzZlfr0qWLq4VBv9WrV8/omHbt2uVqar2qNaXWOrKH2k/DfWrixIluzqJFi1ytbdu2sbFaTyroPwycNvN7WdjQwkxfQ4bvGbW3rVy50tXU+0GFxVc06poobEJnZvb111/Hxqqxwu9+9ztX++STT2JjdY5TTUVUQHko6Xk2vC5TX099JlHn+o0bN8bG5557rptz8sknu1q4f7du3drNmTx5sqsNHz7c1VB6VOi9uk5Kcn2lPg+Hj1PPrRr00HQie/Tu3dvVvvzyS1d7+eWXXS3cX0qzQaFq0jBr1ixXUw1HQ6pJ4GeffRYbf/zxx4kepxoAhXt2kmZqB8Nv2AEAAAAAAAApwg07AAAAAAAAIEW4YQcAAAAAAACkSNZl2Kk8EJVlkiTDTuUtJaGylJLmf6msK6RPmFOispsyzY9TGWUqr2LUqFGx8RdffOHmqFydjz76yNWOO+44V0Nmku43YQaCeu+rfJrw+VXeUVLhelS5SOr7CfNN1FpX1D4YZlskyW9Sz6UyMlSeIEpHixYtXE3tb0nOfUkyNBWV96m+nlrXKh8SFZPaX5PsSffdd5+rqaym8FpwzZo1bo6qqeMKsz1VfqO6hqxfv35sfOyxx7o5CxcudDVl8eLFieZVNFu3bnW1MOeyR48ebs7RRx/tai+88EJsHOYYHozaA8PXPC8vz81R59lwHahrQ3XdoM6F4R7YrVs3NydcY2Y+GznMTjbTebUoWyofU62rJNQ5M7wOU7mL2bqPHAmSZMq1b9/e1cJMUDOdBbt8+fLY+MYbb0x0XOH+qY5T7eH//d//7WrTp0+PjdU16xNPPOFq4V6p9mZ1f0hljPbq1Ss2VtcXSfEbdgAAAAAAAECKcMMOAAAAAAAASBFu2AEAAAAAAAApwg07AAAAAAAAIEWyrumECvRTQbTVqlUr8blUAGsSKsAzadOJJEGQKH9hM4CVK1e6OSpwWjURCMM5VeOU1atXu1q4hteuXevmqGBhFRB6+eWXuxoys337dlcrLCwscV6DBg3cHBX0GwZRq9ByFXyt1mMYpqqaO6jnSrJPqcdlSjUXCKkQWNVsAKWjadOmrrZjxw5XU01EwnUXNvFJ+jWTNnhR85o1a5boayL9kl5f/cd//Eds/N5777k5/fr1c7Vw/2ndurWboxo+1K1b19XCgH4V2K+aRYXXtvPmzXNzVCC4uo4Nm2RNnTrVzVGNGMrLxo0bXW39+vWu1rBhQ1cLv9f+/fu7OaqZQ7hvqX1FfY5Q571wX0x6fg4b46h9TF17hkHnZv5cqM6pKpQ9XJ/qnKqaD6j3Q7t27VwNmVGvn1rH4d6YpOGikuQzM7KLup+iPmd26tTJ1caPHx8b33333W7O7bff7mpJPluohkt/+MMfXC383Hzttde6OWpP/elPf/qDz3Mw6lp32LBhiR6bBHeHAAAAAAAAgBThhh0AAAAAAACQItywAwAAAAAAAFKEG3YAAAAAAABAimRd0wkV8qtC4FU4Z0iFuSehQj1VTQW803SiYti1a1dsvGnTJjdn3bp1rqbCpGfMmBEbqxBq1Xxgy5YtJRylf24zHaq9YsWK2LhRo0ZuTtJg7yOJel+rUOa2bdu6Wvj+Ly4udnOqVq3qamH4r/p6am9RwvBrtS+qtRdSAchqL1OhrCG1ztTjwudXx6neSygdKqB87ty5rrZhwwZXC1/PJE1FzMyaN28eG69Zs8bNUQ0satas6WqqEQzSL9MmOGZmV155ZWysGqeo5jVh0wAVwJ6Xl+dq27Ztc7XatWv/4HMf7BjCx4XNqsz0uUC9t8L3w6uvvurmpKnphAo6V+9zdb4MHztw4EA3R51fkoTsq2s89RkkbCSmHqe+n3CPqlWrlpsTXoua6fN4eH2h9uoTTjjB1WbPnh0bq/WkGmZNmjTJ1Wg6UXqSNjxJIsm1vZqj3m8of+F7NNN7DeoeiHrcqlWrXG3w4MGx8QMPPODmqPPvr371q9hY7TdPP/20q6nr0dDNN9/saqNHjy7xcZ988omrqUaNffr0cTX1eTtT3B0CAAAAAAAAUoQbdgAAAAAAAECKcMMOAAAAAAAASJGsy7BTf1+tcoxU9lQo0wy7vXv3JppHJljFFebHNGnSxM1ZuHChq6l8kzD7Rj0uzAMwM5s2bVpsvGTJEjdHZbMcf/zxrqby01AylY+pJMnISZrNlGTfUHk4KhcpfP6kGShhroQ6zkzzOFUWXZJ8P7VfJ8l5RGZUHqfKRVL5KeFrrDLmlDADKczeNNPvj/r16yeadyQ7lGy4sjyGUNJjGjVqlKv1798/NlZrYPXq1a4Wrtf58+e7Obm5ua6mvp/8/PzYWK1Ndc169tlnx8YzZ850cz777DNXU99PeM3x1VdfuTlpovLQGjZs6Goqzy38XidPnuzmqPyjMC9OrRWVKac+W4TnyzDT7mDCdaCOoV69eq6mshPDvCh1vdi9e3dXC9dUuH7NzDp16uRqat2h9CT5DKvmJT3vhfus+npJMolx+CXNsA6F18tqn7rkkktc7YYbbnC18LEXXnihm/PWW2+5Wnhdqc5NTz75pKv17t3b1Z5//vnYOEkuqaI+T6lsvSFDhmT0/EnxG3YAAAAAAABAinDDDgAAAAAAAEgRbtgBAAAAAAAAKcINOwAAAAAAACBFsq7phAos37lzp6slaSiRNAg7pII4VdDn4Q50RukJ11m3bt3cHBXOq8Kqw6DfF1980c1p3bq1q7333nuxcdeuXd2coUOHupoK8Cc8NjMqjFQ1nVHv/8qVK8fGYTi2md7Ptm7dGhurZhIqtFwJg1NVWK1q3NCgQYMSH6f23fB7TipJGL1aw+px6jXLNIz2SKYCidU5TYVVh3tQ0nPhscceGxu/++67bo5aY2ptZBrGna3U9x/+jNT7Ken7LslrnOn78KabbnK1lStXulrYiOLLL790czZv3uxqSfYttc7VNUDYEEDt8Zs2bXK1K664IjbesWOHm1O7dm1Xa9y4cYnHlfbz//Tp010tPAeZmRUVFbla2NRj6tSpbo66fgupkPE6deq4mnpdwuZU6rOFelz4uqh1qGpqLRYWFsbGa9ascXM6duzoauF6Ve8Pdc2zbt06V0PpSXq+CuclbVYRrj21/jO9nkPZCvdL1QDmww8/dLV///d/j43bt2/v5rz88suu1qNHD1cLm0WsWrXKzRk2bJirheft5557zs0588wzXe2ee+5xtdKStBlfo0aNyuwYzPgNOwAAAAAAACBVuGEHAAAAAAAApAg37AAAAAAAAIAU4YYdAAAAAAAAkCJZ13RCBex+8803rpYk3FiFkyehHqdC2VUNFVMYzGvmmwOY6fDPMLBXNY9QIdTNmzePjbt06eLmzJs3z9VUUKxqXICSqaBoRQWuhyG+6jVIEiysAsPV3qLChsPHqmNQzxU+Tn1/Kqg101D5MLTbzB+rOnZ1XOp9GQaTo2RqPanXXK2f8HVp165doq950kknxca///3vS3xuM/0+DUOQmzZtmugYslWSvSZp6H1pmjZtWmx83333uTmLFy92tT59+rjaG2+8ERurxim1atVytXDfUs0dVEMptd+F7xEV4q+Oq27durFxbm6um6OaDakg7LAhUPjc5W3t2rWx8YoVK9ycgQMHuppqThH+LCdOnOjmqM8IVatWLeEokwfxZ9rgJlxnqrmDCnNXTTTCfXjXrl1ujlqL4eeZDRs2uDlJ94Vx48bFxqNHj3ZzkIxqXKLWY9ImEyVR5/YkzRtRttRrPmnSpNhYXRv/+te/drXOnTvHxmGjIzOz4cOHu9qYMWNcLbxmV/vNsmXLXO3zzz+PjVXDxdJsMKF+fknuzag9vH///qVyTAfDb9gBAAAAAAAAKcINOwAAAAAAACBFuGEHAAAAAAAApAg37AAAAAAAAIAUybquB3Xq1HE1FcSrggZDKug8CdV0QoXF0nSi4mrbtm1srAJg1eu7ceNGVwsbVqxZs8bNCUOi1TGoEMwwRPRgatSokWge4lSYvQqrThKEr8LB1b6hniukAoKThMOrx6nvJwzpzsvLc3PU+lfPn+n3E74n6tWr5+aoY0+y96Nk+fn5rqbWq1p3LVq0iI3DvexgwgBi1cRn/fr1rqaCt8N5R3rTiSRUKL16DVRt4cKFsbFqiLRkyZISa88995ybM3v2bFdbunSpq3355ZexcatWrdycjh07ulrYzECdx9UepRpYdOrUKTZWDR9USHj4s1fXteo6QTWsCq9t09Z04tVXX42NVRMOFWKuft5ff/11bNyhQwc3RzUNS9JoRK0xdS0YnpvUHqUC2MO1or4/1TBDfQYJX3PVMECtlbAhk2qKdvrpp7uaahSizhnIjLrmUntCuGaSNjwJqesm9Z7A4RU2mDAz+8///M/YWDVgUmvlsssui41nzZrl5jzxxBOupq69w/2lSZMmbo5qyhQ2HJowYYKbc7ipn5U6Rzds2LDE58r0M5AZv2EHAAAAAAAApAo37AAAAAAAAIAU4YYdAAAAAAAAkCJZF6Km/q5Y5ers27evxOfKNNdL5UeoDB2Vr4SKIcyBUH+fryT5G/cwv8XMbOXKla42YMCA2Fjl8aBsqcyXpHkE4V7Vr18/N2fr1q0ZHZfKj1PHFR6DytZRwv1TZQCp/VPlN4R7o9rD1ftr+fLlsbHKQVN7v8odxI+n8ojU66syOdV6yUTLli1dTWUnqfydMButV69epXJM2eS8886LjVVGmspSUu+7QYMGxcbt27d3c84880xXC7M91ePU9dyqVatcLcx0Xbx4sZujsvXCTL527dq5OWr/VvmNYZbf3Llz3ZwkOTcqgyxprXHjxq6WJldffXWpPVeYM6f2guuuu87VwpxNdb2ufo7q+cPzqnpNVP52uH5Ubp/KH1TnuPB9pPZJtYZvvfVWV0uC/bRsqaxEtW8kyaxTn0/Dx6nPtbm5uSU+Nzx1TTRnzpzYuHnz5m6Oysx86623XC18H6s9Qh3D9ddfHxur9/Abb7zhairXMvwMMmXKFDdHHbv6/BtKmgMXzksyR0mazVzW+A07AAAAAAAAIEW4YQcAAAAAAACkCDfsAAAAAAAAgBThhh0AAAAAAACQIlnXdEKFuaoQ2CRBnCqoUQnDaFVAofp6tWrVSvT8KDth2GqSdZFU0mDMMEh448aNbk6HDh1cLQxNT9p0QgXMhkrz55DNVNi5avigQqDDwN7TTjvNzZk0aZKrFRQU/ODzmOnXWB1ruHepJhcqDDusqcclaeyjqIYEvXv3drU333wzNlbBtyqYecuWLRkdF+JUCPv27dtdLWwOYlZ6jT/UPrV582ZXU40R1LXCkWz8+PGuNnHixNhYXROp95g6z82ePTs2DvcxM7OioiJXC89zs2bNcnPU66tCtcN9qri42M1R59Fzzz03Nt6wYYObM2HCBFdTe+CoUaNi4w8//NDNUdeGYRMfdX2hrnXVOg/fp6qRR7YIG9N8/PHHbo46Z4fnuKR7llr7u3fvLvFx6n0Ufk31WqrnVuf/8DpBHefnn3/uameccYY/2ARfLwmuMzOn1kuSz55JGn+Z+fWhmk6oxlMo2bvvvutq06ZNi43VeahatWqups4V4byk17xhI4W1a9e6OcOGDXM11Uzx7bffjo0XLFjg5txyyy2u1qNHjxKPM2ljvyTzksxRzX7UZ/LSOqaDPjbjRwIAAAAAAAAoddywAwAAAAAAAFKEG3YAAAAAAABAinDDDgAAAAAAAEiRrGs60aRJk1J7LhXwqIQhgirAM2nQJ7JH0kDdMEh45syZbk7Tpk1drU2bNmV6XMhMTk6Oq6lg6HCvUoHhSfYINUc9lwpAD0OK1RwVth3ueSpAXgUgq+MKA79VoLsKNw5/zqpZi2qYoY4LP54KGlY/22+++cbVVIB1Jpo1a+Zq06dPdzX1nmzbtm2pHEO2GDJkiKtdccUVsfGUKVPcnDlz5riaep8vW7YsNlZNS5RwT1J7lNoz1FoMg9q7d+/u5qhQ6Jdffjk2Vuvptttuc7Xf/OY3rhbq2LGjq6nmLWHTCUU1T1CPC1+fwsLCEp/7cArPaUlC8c2SnV9UM5IkjelUwwfVtES9BuFaV2tY7Ylhkxf1PS9evNjVWrdu7Woh9flm3bp1JT4uKa4zy5Z6XydpjKLWuhI2INi5c6ebk/QzMuL+/u//3tUGDBgQG7/++utuzrx581wtPK+a+c8bmzZtcnPUtXF4rab2g7feesvVJk+eXOJzPfHEE27OBRdc4GqHm7o3E/rqq69c7Z133imLw/lB/IYdAAAAAAAAkCLcsAMAAAAAAABShBt2AAAAAAAAQIpkXYadylJSWQpJ/o5fZVYoYT5F0kyppBkuKDtpzNlo3Lixq6lsxiR5FWotpvF7rqhWrFjhaioTQWXP9OrVKzZWuUVqDwrzk5Lk9pjpHL0kX09lpWzevDk2VnkYKudJ5UqFPxv1uG3btrlay5YtY+OFCxe6OSr7Ue27YX4ISta3b19XU5k26rVTe1wmjjvuOFf78ssvXS3M4zFLlvN0JFHv87Fjx5b4uJUrV7raSy+95Gph5ovaO5cuXepqYXaSev+qY69du7arhXvNp59+6uaoPfCuu+6KjZNk0yU1f/58V1PvjzCnT53bk157Ll++PDbu169ficd5OIXXKEmvWdR5L6R+RrVq1XK1cJ2pNbZgwQJXy83NdbXw/KjWvsphrFevXmys9tdwjpm+3gjPvepxixYtcrXwukR9f1xnHn5qH1Q5iOFro/ITlfA6Vu0jap0hMx06dIiNb7311kSP27Jli6uFubLqNQ/PAWY+B1rlfarPnb/4xS9c7dprr3W1NEqyhlVevDpnlDXebQAAAAAAAECKcMMOAAAAAAAASBFu2AEAAAAAAAApwg07AAAAAAAAIEWyrumECpdWIfAqJDWUtClEGHSbNNRThb4CKlhYrcWaNWsejsPBD1DBrUoYnG5m9pOf/CQ2zs/Pd3NWrVrlai1atIiN1Z4Xhsea6X0wDIZWjS9UKGsYzL5s2TI3p27duq6m1my4D06YMMHNGTZsmKs1b948Nn7xxRfdnJEjR7paeYTFZiO1T6mgfxWwrtZsJlSzk6RNXwhFL1kYYq5ec9XYRTWrSNLAYsmSJa4WNpP5+uuv3RzVuEHtuc2aNYuNVdMStdckkWnw/umnn+5qqnlCeA2g1rmqqSYaHTt2jI0vu+yykg4za6ggddVQIjxPqOYqjRo1SvQ1w+sEdT1Xv359VwuD/tXrq85nu3btcrUkjTxatWrlamHToKRNJ1C21BpKco2XVPg41TAsSZMXlC3VaPOYY445/AdSQSVZw5dcckmiWlnjN+wAAAAAAACAFOGGHQAAAAAAAJAi3LADAAAAAAAAUoQbdgAAAAAAAECKHBGJkSp0U4VQh+GNYeDyweTk5MTGxcXFiR6Xl5eXaB4qpkzDXlWId2FhoaslCTwmWL1sqbDu1atXu5oKZVavc0jtU+PGjYuNVWh5uCeZ6WY4YXMK1axCrbOwpvYytfZUUPKzzz4bG6vGFOr5R40aFRv/7Gc/c3NUmHhpNTyAp16nMDjdzDdOyZQKXFevr1qLYVMCFaZ+pFNNJsqSCr0PayeccMLhOZgfKdNz7V/+8pdSPhL8kDlz5rha2IzEzIfsh80XzMwaNmzoaqrhQ7gHqvOz2svCRhTqekAdl9oDw+Yj6npAvd/V10T5S/q6hNee6nVPck2kvt7hPj8ARzJ2YgAAAAAAACBFuGEHAAAAAAAApAg37AAAAAAAAIAU4YYdAAAAAAAAkCJZ13Riw4YNrhaGx5rpoNYtW7bExiqAPQyBVY9TX2///v2upoLokd3Uax6GVQ8ePLjMnhulS4Xsl2YzmauvvtrVpk+fHhs/88wzbs7mzZtdbeDAga4WBrqrx6l98JtvvomNq1Txp5L58+e72tSpU11txIgRsfEFF1zg5iRB04Dyt337dldTTZimTZtWKl9Pnce3bt3qauo9uX79+tiY9QNkP9UoIryGNzNbsWJFbKwC9sM5ZmY7duxwtTDoX50b1Tk0FO5ZZnp/rV27tqvl5+fHxqrxz2effeZqF198cWysmlBxnXn4qeYm6lotbHiiPp+q5wobUajzqjrfAygb/IYdAAAAAAAAkCLcsAMAAAAAAABShBt2AAAAAAAAQIpkXYbd0Ucf7Wonnniiq4V/n29mtnbt2thY5dUpAwYMiI1Vrs7OnTtdrWPHjomeH9kjSdZHs2bNXC3Mocj0uVG6SjOHMunr16tXr9j4kUcecXOmTJniavPmzXO1cF9q3bq1m7Nnzx5Xq1OnTmys9tPjjjvO1a699lpXyzQ7LPzZq5zQo47y/58U75Oyc+mll7qaWovqPJ2JM844w9UWL17sak2bNnU1tdYBZDd1Dnr//fddrVatWrFx3bp13Zzdu3e7mjoXho9dvXq1m6Ou8cLPIOq5VbaeqoXZejVr1nRzTj31VFdr27atq4U4px5+KpN4yJAhrhau0Xr16rk5ai0sX768xK/Xp0+fEo8TQOngN+wAAAAAAACAFOGGHQAAAAAAAJAi3LADAAAAAAAAUoQbdgAAAAAAAECKVIpKMzUdAAAAAAAAwCHhN+wAAAAAAACAFOGGHQAAAAAAAJAi3LADAAAAAAAAUoQbdgAAAAAAAECKcMMOAAAAAAAASBFu2AEAAAAAAAApwg07AAAAAAAAIEW4YQcAAAAAAACkCDfsAAAAAAAAgBT5fyo66xTfr2jBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    plt.figure(figsize=(plt_images * plt_size, plt_size))\n",
    "\n",
    "    for i in range(plt_images):\n",
    "        plt.subplot(1, plt_images, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_train[i, :, :, :].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap=\"gray_r\")\n",
    "        plt.title(f'Class: {y_train[i].item()}')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb95fcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mp/.pyenv/versions/3.10.10/envs/kma-nn-3.10.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# define_model\n",
    "from optuna.trial import TrialState, Trial\n",
    "\n",
    "def define_model(trial: Trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    conv_kernel_3 = 3\n",
    "    pool_kernel_2 = 2\n",
    "\n",
    "    in_features = 1\n",
    "    image_size = [IMAGE_SIZE, IMAGE_SIZE]\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f'n_units_l{i}', 4, 128, 4)\n",
    "        layers.append(torch.nn.Conv2d(in_features, out_features, kernel_size=conv_kernel_3, stride=1, padding=(conv_kernel_3 - 1) // 2))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.MaxPool2d(kernel_size=pool_kernel_2, stride=pool_kernel_2))\n",
    "        in_features = out_features\n",
    "        image_size[0] //= pool_kernel_2\n",
    "        image_size[1] //= pool_kernel_2\n",
    "\n",
    "    layers.append(torch.nn.Flatten())\n",
    "    layers.append(torch.nn.Linear(in_features * image_size[0] * image_size[1], CLASSES_N))\n",
    "    layers.append(torch.nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return torch.nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, optimizer, scheduler):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (X_train, y_train) in enumerate(train_loader):\n",
    "        if batch_idx * len(X_train) >= N_TRAIN_EXAMPLES:\n",
    "            break\n",
    "        data, target = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    validation_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X_valid, y_valid) in enumerate(validation_loader):\n",
    "            if batch_idx * len(X_valid) >= N_VALID_EXAMPLES:\n",
    "                break\n",
    "            data, target = X_valid.to(device), y_valid.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            validation_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_validation_loss = validation_loss / len(validation_loader)\n",
    "    avg_accuracy = correct / min(len(validation_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return avg_validation_loss, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(torch.nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super(MyNN, self).__init__()\n",
    "    conv_kernel_3 = 3\n",
    "    pool_kernel_2 = 2\n",
    "\n",
    "    in_features = 1\n",
    "    out_features = 24\n",
    "    image_size = [IMAGE_SIZE, IMAGE_SIZE]\n",
    "\n",
    "    self.conv = torch.nn.Conv2d(in_features, out_features, kernel_size=conv_kernel_3, stride=1, padding=(conv_kernel_3 - 1) // 2)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "    self.pool = torch.nn.MaxPool2d(kernel_size=pool_kernel_2, stride=pool_kernel_2)\n",
    "\n",
    "    in_features = out_features\n",
    "    image_size[0] //= pool_kernel_2\n",
    "    image_size[1] //= pool_kernel_2\n",
    "\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.relu_out = nn.ReLU()\n",
    "    self.fc = torch.nn.Linear(in_features * image_size[0] * image_size[1], CLASSES_N)\n",
    "    self.sm = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.flatten(x)\n",
    "    x = self.relu_out(x)\n",
    "    x = self.fc(x)\n",
    "    x = self.sm(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "avg_accuracies = []\n",
    "avg_losses = []\n",
    "\n",
    "def train_loop(model: nn.Module, optimizer, scheduler, train_loader, num_epochs=EPOCHS):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        average_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = correct / N_TRAIN_EXAMPLES\n",
    "\n",
    "        avg_accuracies.append(avg_accuracy)\n",
    "        avg_losses.append(average_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "    plt.plot(range(1, num_epochs + 1), avg_losses, label='Average Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), avg_accuracies, label='Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.3770\n",
      "Epoch [2/5], Loss: 0.2492\n",
      "Epoch [3/5], Loss: 0.2304\n",
      "Epoch [4/5], Loss: 0.2281\n",
      "Epoch [5/5], Loss: 0.2278\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MyNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "\n",
    "train_loop(model, optimizer, scheduler, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.0117, Accuracy: 0.1500\n",
      "Epoch 2/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 3/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 4/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 5/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 6/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 7/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 8/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 9/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 10/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 11/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 12/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 13/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 14/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 15/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 16/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 17/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 18/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 19/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 20/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 21/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 22/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 23/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 24/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 25/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 26/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 27/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 28/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 29/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 30/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 31/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 32/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 33/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 34/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 35/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 36/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 37/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 38/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 39/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 40/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 41/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 42/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 43/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 44/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 45/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 46/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 47/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 48/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 49/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 50/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 51/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 52/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 53/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 54/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 55/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 56/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 57/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 58/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 59/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 60/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 61/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 62/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 63/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 64/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 65/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 66/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 67/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 68/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 69/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 70/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 71/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 72/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 73/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 74/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 75/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 76/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 77/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 78/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 79/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 80/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 81/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 82/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 83/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 84/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 85/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 86/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 87/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 88/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 89/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 90/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 91/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 92/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 93/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 94/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 95/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 96/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 97/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 98/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 99/100, Loss: 0.0111, Accuracy: 0.1500\n",
      "Epoch 100/100, Loss: 0.0111, Accuracy: 0.1500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 100  # Adjust as needed\n",
    "avg_accuracies = []\n",
    "avg_losses = []\n",
    "\n",
    "model = MyNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (X_train, y_train) in enumerate(train_loader):\n",
    "        if batch_idx * len(X_train) >= N_TRAIN_EXAMPLES:\n",
    "            break\n",
    "        data, target = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    validation_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X_valid, y_valid) in enumerate(validation_loader):\n",
    "            if batch_idx * len(X_valid) >= N_VALID_EXAMPLES:\n",
    "                break\n",
    "            data, target = X_valid.to(device), y_valid.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            validation_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_validation_loss = validation_loss / len(validation_loader)\n",
    "    avg_accuracy = correct / min(len(validation_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_accuracies.append(avg_accuracy)\n",
    "    avg_losses.append(avg_validation_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}, Loss: {avg_validation_loss:.4f}, Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Visualize learning curves\n",
    "plt.plot(range(1, EPOCHS + 1), avg_losses, label='Average Loss')\n",
    "plt.plot(range(1, EPOCHS + 1), avg_accuracies, label='Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective\n",
    "# CNN - Початкову кількість шарів та їх параметри.\n",
    "# CNN: spatial relationships, translation-invariant features\n",
    "import torch\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "accuracies = []\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(device)\n",
    "    print(model)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss, avg_accuracy = train_loop(model, optimizer)\n",
    "        trial.report(avg_accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def objective(trial):\n",
    "    global train_loader, validation_loader, avg_accuracies, avg_losses\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(device)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * batch_size >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * batch_size >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        accuracy = correct / min(len(validation_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        average_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = correct / N_TRAIN_EXAMPLES\n",
    "\n",
    "        avg_accuracies.append(avg_accuracy)\n",
    "        avg_losses.append(average_loss)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce34bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-06 09:21:30,688] A new study created in memory with name: no-name-34c4f5e0-7e1f-49a2-9403-c8f6b62667b9\n",
      "[I 2023-11-06 09:21:32,215] Trial 0 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 24, 'n_units_l1': 92, 'n_units_l2': 96, 'optimizer': 'RMSprop', 'lr': 8.071231324343542e-05}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-11-06 09:21:33,203] Trial 1 finished with value: 0.05 and parameters: {'n_layers': 3, 'n_units_l0': 24, 'n_units_l1': 12, 'n_units_l2': 92, 'optimizer': 'SGD', 'lr': 0.08883251532487642}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:33,843] Trial 2 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 16, 'n_units_l1': 12, 'optimizer': 'SGD', 'lr': 0.00012793685963352462}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:35,824] Trial 3 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 104, 'n_units_l1': 120, 'optimizer': 'SGD', 'lr': 0.0005442079189911758}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:37,808] Trial 4 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 104, 'n_units_l1': 124, 'optimizer': 'SGD', 'lr': 0.048014465563167026}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:39,582] Trial 5 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 92, 'n_units_l1': 20, 'n_units_l2': 88, 'optimizer': 'RMSprop', 'lr': 0.01685850339079025}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:39,755] Trial 6 pruned. \n",
      "[I 2023-11-06 09:21:41,056] Trial 7 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'n_units_l1': 96, 'n_units_l2': 116, 'optimizer': 'RMSprop', 'lr': 0.004925714357791363}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:41,855] Trial 8 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 100, 'optimizer': 'RMSprop', 'lr': 0.00038328484782066975}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:43,847] Trial 9 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 108, 'n_units_l1': 116, 'optimizer': 'SGD', 'lr': 0.059934737402874125}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:44,579] Trial 10 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 60, 'optimizer': 'Adam', 'lr': 0.0037982391257763122}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:45,380] Trial 11 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 68, 'optimizer': 'Adam', 'lr': 0.0010881849861687776}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:46,314] Trial 12 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 124, 'optimizer': 'RMSprop', 'lr': 0.010906803813708251}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:47,120] Trial 13 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 76, 'optimizer': 'RMSprop', 'lr': 0.08124747220419774}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:48,186] Trial 14 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 36, 'n_units_l1': 60, 'optimizer': 'Adam', 'lr': 0.0014118720700516086}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:48,870] Trial 15 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'optimizer': 'SGD', 'lr': 0.018338747816550916}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:49,295] Trial 16 pruned. \n",
      "[I 2023-11-06 09:21:51,030] Trial 17 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 124, 'n_units_l1': 4, 'optimizer': 'RMSprop', 'lr': 0.005079512379786504}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:51,328] Trial 18 pruned. \n",
      "[I 2023-11-06 09:21:52,332] Trial 19 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 44, 'n_units_l2': 128, 'optimizer': 'Adam', 'lr': 0.09830427273412219}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:52,812] Trial 20 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 28, 'optimizer': 'SGD', 'lr': 0.0018146773516489068}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:54,776] Trial 21 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 108, 'n_units_l1': 88, 'optimizer': 'SGD', 'lr': 0.03707199189734561}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:56,625] Trial 22 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 96, 'n_units_l1': 108, 'optimizer': 'SGD', 'lr': 0.024876199213280718}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:59,086] Trial 23 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 112, 'n_units_l1': 84, 'n_units_l2': 68, 'optimizer': 'SGD', 'lr': 0.08506261060497579}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:21:59,881] Trial 24 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 88, 'optimizer': 'SGD', 'lr': 0.01073355544725977}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:01,818] Trial 25 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 116, 'n_units_l1': 48, 'optimizer': 'RMSprop', 'lr': 0.05287666502630879}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:03,510] Trial 26 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 80, 'n_units_l1': 72, 'optimizer': 'SGD', 'lr': 0.02556527495733542}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:04,334] Trial 27 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'optimizer': 'SGD', 'lr': 0.09911670781731856}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:04,868] Trial 28 pruned. \n",
      "[I 2023-11-06 09:22:06,744] Trial 29 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'n_units_l1': 28, 'n_units_l2': 72, 'optimizer': 'RMSprop', 'lr': 0.00022561594420383228}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:08,225] Trial 30 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 60, 'n_units_l1': 80, 'optimizer': 'RMSprop', 'lr': 0.0031895203553940757}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:08,997] Trial 31 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 60, 'optimizer': 'Adam', 'lr': 0.002153538433564759}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:09,442] Trial 32 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'optimizer': 'Adam', 'lr': 0.0008784436507862322}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:09,990] Trial 33 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 28, 'optimizer': 'Adam', 'lr': 0.00585861697546339}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:10,394] Trial 34 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 12, 'optimizer': 'Adam', 'lr': 0.05007287597314317}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:10,579] Trial 35 pruned. \n",
      "[I 2023-11-06 09:22:10,976] Trial 36 pruned. \n",
      "[I 2023-11-06 09:22:12,092] Trial 37 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 40, 'n_units_l1': 56, 'optimizer': 'Adam', 'lr': 0.01869720665889321}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:14,386] Trial 38 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'n_units_l1': 72, 'n_units_l2': 104, 'optimizer': 'RMSprop', 'lr': 0.002615031344311629}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:14,535] Trial 39 pruned. \n",
      "[I 2023-11-06 09:22:16,278] Trial 40 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 60, 'n_units_l1': 128, 'optimizer': 'Adam', 'lr': 4.9086120602779246e-05}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:17,097] Trial 41 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 68, 'optimizer': 'Adam', 'lr': 0.0012890569654157307}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:17,992] Trial 42 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 104, 'optimizer': 'Adam', 'lr': 0.003336568856008806}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:18,882] Trial 43 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'optimizer': 'Adam', 'lr': 0.0004009977296186638}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:19,472] Trial 44 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 32, 'optimizer': 'RMSprop', 'lr': 0.0009052517981355715}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:20,269] Trial 45 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 48, 'optimizer': 'Adam', 'lr': 0.05686777764372523}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:21,211] Trial 46 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 76, 'optimizer': 'RMSprop', 'lr': 0.029713570952529425}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:21,318] Trial 47 pruned. \n",
      "[I 2023-11-06 09:22:22,250] Trial 48 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'optimizer': 'Adam', 'lr': 0.014684607614215302}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:22,605] Trial 49 pruned. \n",
      "[I 2023-11-06 09:22:23,317] Trial 50 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 44, 'optimizer': 'RMSprop', 'lr': 0.004174049656096686}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:23,404] Trial 51 pruned. \n",
      "[I 2023-11-06 09:22:23,485] Trial 52 pruned. \n",
      "[I 2023-11-06 09:22:24,438] Trial 53 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'optimizer': 'RMSprop', 'lr': 0.0018041912204098266}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:25,360] Trial 54 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'optimizer': 'RMSprop', 'lr': 0.07201712496652124}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:26,259] Trial 55 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'optimizer': 'SGD', 'lr': 0.014052615681637372}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:28,184] Trial 56 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 100, 'n_units_l1': 96, 'optimizer': 'RMSprop', 'lr': 0.008975604805591744}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:28,535] Trial 57 pruned. \n",
      "[I 2023-11-06 09:22:28,889] Trial 58 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'optimizer': 'Adam', 'lr': 0.020856773363301953}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:29,307] Trial 59 pruned. \n",
      "[I 2023-11-06 09:22:30,891] Trial 60 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 64, 'n_units_l1': 76, 'optimizer': 'RMSprop', 'lr': 0.0238596856438366}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:31,705] Trial 61 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'optimizer': 'RMSprop', 'lr': 0.07653319185805212}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:32,597] Trial 62 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 80, 'optimizer': 'RMSprop', 'lr': 0.08427603746355143}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:33,367] Trial 63 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'optimizer': 'RMSprop', 'lr': 0.056237613864916866}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:34,181] Trial 64 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 68, 'optimizer': 'RMSprop', 'lr': 0.09930548646106158}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:35,094] Trial 65 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 76, 'optimizer': 'Adam', 'lr': 0.042056994715585966}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:35,965] Trial 66 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 100, 'optimizer': 'SGD', 'lr': 0.03212275107528949}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:37,895] Trial 67 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 88, 'n_units_l1': 104, 'optimizer': 'RMSprop', 'lr': 0.019530124719126792}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:38,816] Trial 68 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'optimizer': 'SGD', 'lr': 0.06951550314706673}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:39,220] Trial 69 pruned. \n",
      "[I 2023-11-06 09:22:39,384] Trial 70 pruned. \n",
      "[I 2023-11-06 09:22:40,109] Trial 71 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'optimizer': 'SGD', 'lr': 0.04779637419143042}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:40,851] Trial 72 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'optimizer': 'SGD', 'lr': 0.016508959796092883}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:41,736] Trial 73 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'optimizer': 'SGD', 'lr': 0.010698142795417373}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:41,827] Trial 74 pruned. \n",
      "[I 2023-11-06 09:22:42,705] Trial 75 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 80, 'optimizer': 'Adam', 'lr': 0.06526589200302194}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:43,873] Trial 76 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 48, 'n_units_l1': 12, 'optimizer': 'SGD', 'lr': 0.027844740372701276}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:44,820] Trial 77 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 116, 'optimizer': 'Adam', 'lr': 0.09562943052646765}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:45,310] Trial 78 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 24, 'optimizer': 'SGD', 'lr': 0.022316096635478337}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:45,704] Trial 79 pruned. \n",
      "[I 2023-11-06 09:22:46,555] Trial 80 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'optimizer': 'Adam', 'lr': 0.04605177899159632}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:46,673] Trial 81 pruned. \n",
      "[I 2023-11-06 09:22:46,781] Trial 82 pruned. \n",
      "[I 2023-11-06 09:22:47,391] Trial 83 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 40, 'optimizer': 'SGD', 'lr': 0.0015618588865318995}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:47,499] Trial 84 pruned. \n",
      "[I 2023-11-06 09:22:47,951] Trial 85 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 12, 'optimizer': 'SGD', 'lr': 0.004229081648557348}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:48,722] Trial 86 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'optimizer': 'RMSprop', 'lr': 0.003083989715805598}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:49,661] Trial 87 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 124, 'optimizer': 'SGD', 'lr': 0.00155546009509046}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:50,391] Trial 88 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 44, 'optimizer': 'Adam', 'lr': 0.06140515308619364}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:50,758] Trial 89 pruned. \n",
      "[I 2023-11-06 09:22:51,550] Trial 90 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 60, 'optimizer': 'SGD', 'lr': 0.012540109130711321}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:53,560] Trial 91 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 96, 'n_units_l1': 116, 'optimizer': 'SGD', 'lr': 0.031012966859287904}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:53,965] Trial 92 pruned. \n",
      "[I 2023-11-06 09:22:56,125] Trial 93 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 104, 'n_units_l1': 128, 'optimizer': 'SGD', 'lr': 0.05006707244260595}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:58,351] Trial 94 finished with value: 0.05 and parameters: {'n_layers': 2, 'n_units_l0': 120, 'n_units_l1': 92, 'optimizer': 'SGD', 'lr': 0.07846197038106328}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:22:58,677] Trial 95 pruned. \n",
      "[I 2023-11-06 09:22:59,515] Trial 96 finished with value: 0.05 and parameters: {'n_layers': 1, 'n_units_l0': 68, 'optimizer': 'Adam', 'lr': 0.023292213139060464}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:23:01,598] Trial 97 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 112, 'n_units_l1': 112, 'optimizer': 'SGD', 'lr': 0.035297882350568466}. Best is trial 1 with value: 0.05.\n",
      "[I 2023-11-06 09:23:01,790] Trial 98 pruned. \n",
      "[I 2023-11-06 09:23:02,098] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  25\n",
      "  Number of complete trials:  75\n",
      "Best trial:\n",
      "  Value:  0.05\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 24\n",
      "    n_units_l1: 12\n",
      "    n_units_l2: 92\n",
      "    optimizer: SGD\n",
      "    lr: 0.08883251532487642\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "from optuna.visualization import plot_contour, plot_optimization_history\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "accuracies = []\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most unpredictable class: 0\n",
      "Accuracy for each class: [0.0, 0.0, 0.014, 0.0, 0.994, 0.002, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "best_trial = study.best_trial\n",
    "best_model = define_model(best_trial)\n",
    "best_model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = [0 for _ in range(CLASSES_N)]\n",
    "class_total = [0 for _ in range(CLASSES_N)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in validation_loader:\n",
    "        outputs = best_model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "class_accuracy = [class_correct[i] / class_total[i] for i in range(CLASSES_N)]\n",
    "most_unpredictable_class = class_accuracy.index(min(class_accuracy))\n",
    "\n",
    "print(f\"Most unpredictable class: {most_unpredictable_class}\")\n",
    "print(f\"Accuracy for each class: {class_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "plot_optimization_history(study).show(renderer=\"browser\")\n",
    "hyperparams = [f'n_units_l{i}' for i in range(2)] + ['n_layers']\n",
    "plot_contour(study, params=hyperparams).show(renderer=\"browser\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](charts/optuna-report.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](charts/optuna-objective.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JUPYTER STORES EXECUTION TIME OF EACH CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
